<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="dark">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Thursday Forum References and Notes | Michael T. Stobb</title>
<meta name="keywords" content="">
<meta name="description" content="Lecture 01: How did we get here?
This page contains notes, further readings, and general references for the associated lecture.
The Lecture Slides for the talk are also available (use your arrow keys to advance the slides).
AI Scaling Laws


A great visualization of the current AI investment is available by Reuters. Be sure to keep scrolling through the page to get a real sense for the current size of the AI investment.">
<meta name="author" content="">
<link rel="canonical" href="https://stobb.org/thursday_forum/2025_lecture_01/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.960f1449777f1c27112a84b443014ca324d51065a68183f9694cf5e1f9f1f49a.css" integrity="sha256-lg8USXd/HCcRKoS0QwFMoyTVEGWmgYP5aUz14fnx9Jo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://stobb.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://stobb.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://stobb.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://stobb.org/apple-touch-icon.png">
<link rel="mask-icon" href="https://stobb.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://stobb.org/thursday_forum/2025_lecture_01/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><meta property="og:url" content="https://stobb.org/thursday_forum/2025_lecture_01/">
  <meta property="og:site_name" content="Michael T. Stobb">
  <meta property="og:title" content="Thursday Forum References and Notes">
  <meta property="og:description" content="Lecture 01: How did we get here? This page contains notes, further readings, and general references for the associated lecture.
The Lecture Slides for the talk are also available (use your arrow keys to advance the slides).
AI Scaling Laws A great visualization of the current AI investment is available by Reuters. Be sure to keep scrolling through the page to get a real sense for the current size of the AI investment.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="thursday_forum">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Thursday Forum References and Notes">
<meta name="twitter:description" content="Lecture 01: How did we get here?
This page contains notes, further readings, and general references for the associated lecture.
The Lecture Slides for the talk are also available (use your arrow keys to advance the slides).
AI Scaling Laws


A great visualization of the current AI investment is available by Reuters. Be sure to keep scrolling through the page to get a real sense for the current size of the AI investment.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Thursday_forums",
      "item": "https://stobb.org/thursday_forum/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Thursday Forum References and Notes",
      "item": "https://stobb.org/thursday_forum/2025_lecture_01/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Thursday Forum References and Notes",
  "name": "Thursday Forum References and Notes",
  "description": "Lecture 01: How did we get here? This page contains notes, further readings, and general references for the associated lecture.\nThe Lecture Slides for the talk are also available (use your arrow keys to advance the slides).\nAI Scaling Laws A great visualization of the current AI investment is available by Reuters. Be sure to keep scrolling through the page to get a real sense for the current size of the AI investment.\n",
  "keywords": [
    
  ],
  "articleBody": "Lecture 01: How did we get here? This page contains notes, further readings, and general references for the associated lecture.\nThe Lecture Slides for the talk are also available (use your arrow keys to advance the slides).\nAI Scaling Laws A great visualization of the current AI investment is available by Reuters. Be sure to keep scrolling through the page to get a real sense for the current size of the AI investment.\nThe Standford institute for Human-Centered Artificial Intelligence (HAI) put together the excellent graphic detailing how AI spending is broken down by category.\nThe big paper to read is by Kaplan et al. titled Scaling Laws for Neural Language Models. The authors were all OpenAI researchers and would go on (with significant investor support) to produce some of the best AI models ever created (one of the authors was Dario Amodei who later left OpenAI and cofounded Anthropic, another AI lab that currently produces the Claude AI models). This paper was very much a blend of hard Machine Learning research (note that it does at times get quite technical) and a pitch for financial investors that their money wouldn’t be wasted.\nThe Kaplan paper above found very specific scaling laws for AI improvement, however, later work by Google Deepmind (the AI side of Google) corrected these scaling laws and found that doubling the model size required a doubling in the data size. Unlike the Kaplan paper, this paper is quite technical and a little hard to read without some background knowledge in the subject.\nSome History Thomas Hobbes is perhaps best known for his politcal and social contract theories, much discussed in his magnum opus Leviathan, but fewer people are aware of his idea that “reasoning is just computation”. See the Stanford Philosophy Encyclopedia entry on it for more depth.\nFull chapter V of Leviathan by Hobbes referenced in talk is available here and well worth a read if you haven’t read it in awhile.\nFurther reading on Leibniz ideas on Language and the Mind.\nFurther readings and analysis on Descartian dualism are available here\nFurther readings on the history, implementation, and critiques of the Turing Test are available here. It’s interesting to note that the original Imititation Game imagined by Turing was genedered, where instead of a human and a machine, the two secret people were a man and a woman, where the man attempted to be a woman, and then later switched with a machine. This was discussed more as a “parlor game” to be played amoung friends and less a rigorous test for artificial intelligence, however, in this same article by Turing, he does also describe the form of the imitation game that has become standard and used for the last 70 years.\nFurther reading about Eugene Goostmen, the 2014 chat bot to beat the “Turing Test” for the first time, specifically the 30% threshold first imagined by Alan Turing.\nThe Turing Test is truly defeated as discussed in the 2025 paper by Jones and Bergen titled Large Language Models Pass the Turing Test.\nFull article by Dijkistra for his quote on thinking machines is here\nThe Perceptron Excellent article detailing the history and workings of a basic Perceptron. Definitely something fun to play with and read when you have a chance.\nWelch Labs makes excellent and accurate videos and recently even produced a new textbook. This video goes into quite a bit of detail on the Perceptron itself. It does sometimes get a little technical, but the history and production value are just great.\n",
  "wordCount" : "590",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://stobb.org/thursday_forum/2025_lecture_01/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Michael T. Stobb",
    "logo": {
      "@type": "ImageObject",
      "url": "https://stobb.org/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://stobb.org/" accesskey="h" title="Michael T. Stobb (Alt + H)">Michael T. Stobb</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://stobb.org/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://stobb.org/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://stobb.org/teaching/" title="Teaching">
                    <span>Teaching</span>
                </a>
            </li>
            <li>
                <a href="https://stobb.org/software/" title="Software">
                    <span>Software</span>
                </a>
            </li>
            <li>
                <a href="https://stobb.org/personal/" title="Personal">
                    <span>Personal</span>
                </a>
            </li>
            <li>
                <a href="https://stobb.org/contact/" title="Contact">
                    <span>Contact</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Thursday Forum References and Notes
    </h1>
  </header> 
  <div class="post-content"><h2 id="lecture-01-how-did-we-get-here">Lecture 01: How did we get here?<a hidden class="anchor" aria-hidden="true" href="#lecture-01-how-did-we-get-here">#</a></h2>
<p>This page contains notes, further readings, and general references for the associated lecture.</p>
<p>The <a href="https://docs.google.com/presentation/d/e/2PACX-1vTLaVcNoa7dHYlBRmaX_-6Ynie8RDWHb989P8d8UkfsoOKQzYuYGMlIydZMDcED1MC_ua6ypJwSd8TQ/pub?start=false&amp;loop=false&amp;delayms=60000">Lecture Slides</a> for the talk are also available (use your arrow keys to advance the slides).</p>
<h2 id="ai-scaling-laws">AI Scaling Laws<a hidden class="anchor" aria-hidden="true" href="#ai-scaling-laws">#</a></h2>
<ul>
<li>
<p>A great visualization of the current <a href="https://www.reuters.com/graphics/USA-ECONOMY/AI-INVESTMENT/gkvlqbgxkpb/">AI investment</a> is available by Reuters. Be sure to keep scrolling through the page to get a real sense for the current size of the AI investment.</p>
</li>
<li>
<p>The Standford institute for Human-Centered Artificial Intelligence (HAI) put together the excellent graphic detailing how <a href="https://hai.stanford.edu/ai-index/2025-ai-index-report/economy">AI spending</a> is broken down by category.</p>
</li>
<li>
<p>The big paper to read is by Kaplan et al. titled <a href="https://arxiv.org/pdf/2001.08361">Scaling Laws for Neural Language Models</a>. The authors were all OpenAI researchers and would go on (with significant investor support) to produce some of the best AI models ever created (one of the authors was Dario Amodei who later left OpenAI and cofounded Anthropic, another AI lab that currently produces the Claude AI models). This paper was very much a blend of hard Machine Learning research (note that it does at times get quite technical) and a pitch for financial investors that their money wouldn&rsquo;t be wasted.</p>
</li>
<li>
<p>The Kaplan paper above found very specific scaling laws for AI improvement, however, later work by Google Deepmind (the AI side of Google) corrected these <a href="https://arxiv.org/pdf/2203.15556">scaling laws</a> and found that doubling the model size required a doubling in the data size. Unlike the Kaplan paper, this paper is quite technical and a little hard to read without some background knowledge in the subject.</p>
</li>
</ul>
<!-- raw HTML omitted -->
<h3 id="some-history">Some History<a hidden class="anchor" aria-hidden="true" href="#some-history">#</a></h3>
<ul>
<li>
<p>Thomas Hobbes is perhaps best known for his politcal and social contract theories, much discussed in his magnum opus Leviathan, but fewer people are aware of his idea that &ldquo;reasoning is just computation&rdquo;. See the <a href="https://plato.stanford.edu/entries/hobbes/#2.4:~:text=does%20(Bolton%201977).-,2.4%20Reasoning%20as%20Computation,say%20that%20Hobbes%20was%20%E2%80%9Cprophetically%20launching%20Artificial%20Intelligence%E2%80%9D%20(Haugeland%201985%2C%2023).,-3.%20Materialism">Stanford Philosophy Encyclopedia</a> entry on it for more depth.</p>
</li>
<li>
<p>Full <a href="https://standardebooks.org/ebooks/thomas-hobbes/leviathan/text/chapter-5">chapter V of Leviathan</a> by Hobbes referenced in talk is available here and well worth a read if you haven&rsquo;t read it in awhile.</p>
</li>
<li>
<p>Further reading on Leibniz ideas on <a href="https://plato.stanford.edu/entries/leibniz-mind/#:~:text=finite%20simple%20substances.-,3.%20Language%20and%20Mind,his%20discussions%20bear%20considerable%20relevance%20to%20discussions%20in%20the%20cognitive%20sciences.,-According%20to%20Leibniz">Language and the Mind</a>.</p>
</li>
<li>
<p>Further readings and analysis on Descartian dualism are available <a href="https://iep.utm.edu/descartes-mind-body-distinction-dualism/">here</a></p>
</li>
<li>
<p>Further readings on the history, implementation, and critiques of the Turing Test are available <a href="https://plato.stanford.edu/entries/turing-test/">here</a>. It&rsquo;s interesting to note that the original Imititation Game imagined by Turing was <em>genedered</em>, where instead of a human and a machine, the two secret people were a <em>man</em> and a <em>woman</em>, where the man attempted to be a woman, and then later switched with a machine. This was discussed more as a &ldquo;parlor game&rdquo; to be played amoung friends and less a rigorous test for artificial intelligence, however, in this same article by Turing, he does also describe the form of the imitation game that has become standard and used for the last 70 years.</p>
</li>
<li>
<p>Further reading about <a href="https://en.wikipedia.org/wiki/Eugene_Goostman">Eugene Goostmen</a>, the 2014 chat bot to beat the &ldquo;Turing Test&rdquo; for the first time, specifically the 30% threshold first imagined by Alan Turing.</p>
</li>
<li>
<p>The Turing Test is truly defeated as discussed in the 2025 paper by Jones and Bergen titled <a href="https://arxiv.org/pdf/2503.23674">Large Language Models Pass the Turing Test</a>.</p>
</li>
<li>
<p>Full article by Dijkistra for his quote on thinking machines is <a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD08xx/EWD898.html">here</a></p>
</li>
</ul>
<!-- raw HTML omitted -->
<h3 id="the-perceptron">The Perceptron<a hidden class="anchor" aria-hidden="true" href="#the-perceptron">#</a></h3>
<ul>
<li>
<p>Excellent article detailing the history and workings of a basic <a href="https://perceptrondemo.com/">Perceptron</a>. Definitely something fun to play with and read when you have a chance.</p>
</li>
<li>
<p><a href="https://www.youtube.com/@WelchLabs">Welch Labs</a> makes excellent and accurate videos and recently even produced a new textbook. <a href="https://youtu.be/l-9ALe3U-Fg?si=jL03AZrfhqIom_Qk">This video</a> goes into quite a bit of detail on the Perceptron itself. It does sometimes get a little technical, but the history and production value are just great.</p>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://stobb.org/">Michael T. Stobb</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
